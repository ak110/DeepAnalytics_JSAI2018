m.deepanalytics2@tqzh.tk

######## OSのバージョン、使用ソフトウェア等 ########
1.OSのバージョン
　例）CentOS Linux release 7.4.1708（core）

Ubuntu 16.04.4 LTS

2.使用言語
　例）Python 3.6.3

Python 3.6.4

3.使用ライブラリ・バージョン
　例）numpy 1.13.3

Keras==2.1.5
tensorflow-gpu==1.6.0
horovod==0.12.1  (学習時のみ)
scikit-learn==0.19.1
opencv-python==3.4.0.12
numpy==1.14.2
tqdm==4.19.8
better-exceptions==0.2.1

######## データ及びモデリング内容について ########
※ご提出物内容の理解の為に大変重要となりますので、詳細な記述にご協力下さい。

1.今回のデータや問題の特徴について
　どんな特徴のあるデータだったか？どういうところが難しい問題だったか？
　何を精度向上のポイントとなると仮定したか？その上でどんなアプローチをとったのか？

一般的な画像認識タスクで有効とされる手法をそのまま用い、データ等に特化した手法を使用しなかった。

2.予測ロジック
　例）(１)トレンド考慮の為に、時系列モデルを利用し予測　
      (２)(１)で求めた値を特徴量に加え、Stacking（RandomForest、Xgboost）を用いて最終的な予測値を求める

InceptionResNetV2をクロスバリデーションで15回学習し、それぞれTest-time augmentationを256回実施。
Data AugmentationにはRandom erasingやMixupなどを使用した。

3.工夫点・モデリングの特徴
　ご提出いただいたモデルの優れていると考えられる点も合わせて記述下さい。

データ等に特化した手法を使用していないため、研究のベースラインなどに適切。

4.分析・モデリングから得られた示唆
　なぜ高い予測精度が出せたかやどうすれば更に予測精度が上がると考えられるか等。
　もし他にも試されたが上手くいかなった手法や苦戦したことなどありましたら合わせて記述下さい。

ResNetやDropoutなどの手法は、シングルモデルでアンサンブル効果を出すものという解釈がある。
より大きなモデルをより長時間訓練することにより更なる精度向上が見込めたのではないかと思われる。
(使用したGPUがGTX 1080でありメモリが足りないため試していない)

5.採用したモデリング手法
　例) Stacking（RandomForest + Xgboost）

InceptionResNetV2

######## 提出ソースコードについて ########
1.ソースコード概要
　データ加工・前処理から予測出力までのソースコードの流れを示してください。
　関数定義等されていましたら、名前も記述頂きながら、何を実行されているのかも合わせて記述下さい。

学習時(train.py)は、data.load_data()によりtrain_master.tsvを読み込み、models.create_network()によりモデルを作成して学習。

予測時(predict.py)は、GPU数分の子プロセス(_subprocess())を作成し、models.load()でモデルを読み込み、data.load_data()によりsample_submit.tsvを読み込み、予測。


3.学習部分と予測部分とを独立して実行する手順を示してください

学習部分は train.sh を実行する。
予測結果を再現するには、data/配下に以下のようにデータを配置し、

- data
  - test
    - test_0.jpg ～ test_3936.jpg
  - train
    - train_0.jpg ～ train_11994.jpg
  - master.tsv
  - sample_submit.tsv
  - train_master.tsv

predict.pyのあるディレクトリへ移動して以下のコマンドを実行する。
    
    docker run --runtime=nvidia --interactive --tty --rm --volume=$PWD:/usr/src/app ak110/keras-docker:0.0.1 python predict.py

結果は models/submit.tsv に保存される。


4.学習部分のおおよその実行時間を示してください

GTX 1080×2の環境で9日間程度。


5.予測部分のおおよその実行時間を示してください

GTX 1080×2の環境で29時間程度。


6.ハイパーパラメータについて記述下さい
　ハイパーパラメータとしてチューニングした変数名や、チューニング方法等を記述下さい。
　例）RandomForestのn_estimatorとmax_depthをチューニング変数とし、
　　　Gridsearchにてn_estimator:[100,200]、max_depth:[5,10]でcv=3で探索し、
　　　最も精度の良かったn_estimator=100, max_depth=5を採用した。他の変数についてはデフォルト値をそのまま採用した。

Test-time augmentationの際に画像サイズのパターン (predict.py の _SIZE_PATTERNS) を調整した。
大きすぎてもあまり良くなかったため、学習時のサイズ×(0.75～1.25)とした。


7.乱数の取り扱い方法（シード値等）についてご説明下さい
　シード値が必要な関数や設定したその具体的なシード値等を記述下さい。

クロスバリデーションの分割のために123, 234, 345を使用。(train.shに記載)

また、Test-time augmentationの際に「1234 + tta_index(0～255)」を使用。(predict.pyに記載)


8.参加条件やルール（アンサンブル学習に関する制約等）を満たしていますか？ 

はい


######## アンケート ########
1.今回のコンテストへの参加理由を教えてください

画像認識における最近の動向を実データで試してみるため。

(去年のAIチャレンジコンテストの分類部門にも参加したが、当時はInceptionResNetV2やDenseNetなどがKerasに入っておらず、Random erasingやMixupは発表されていなかった)


2.今回のコンテストにおける実質の作業時間はおよそどれくらいでしたか？

10


3.今回のコンテストについてご感想／ご意見をお願い致します

ルールが不明確でやりにくかった。

経験上、あらゆる手法を制限なしに用いて作成したモデルを更に改善する難易度は、手法が制限された状態で作成されたモデルを改善する難易度に比べて非常に高い。
手法を制限するルールは、既に有効と分かっている手法の代替案を生むばかりになるのではないか。


4.DeepAnalyticsをどこでお知りになりましたか？（選択式）

☐ 同僚・友人・知人からの紹介
☑ Twitter
☐ Facebook
☐ Qiita
☐ udemy
☐ その他: 


5.今後のサービス改善のために、あなたがDeepAnalyticsに期待することを教えてください（選択式）

☐ たくさんのコンテストが開催されていること
☑ コンテスト入賞者のデータ分析手法が開示されていること
☑ サイト上で技術的な質問や議論ができる機能が実装されていること
☐ AIやデータサイエンスに関する記事等が豊富なこと
☐ 求人情報が豊富に掲載されていること
☐ その他: 
